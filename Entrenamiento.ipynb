{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9c311a-bbe3-4437-8853-8656eaafe19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac284d66-405a-4cf0-92a5-0642c2db9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura neuronal\n",
    "class HaloToGalaxyModel(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=1, hidden_dim=64):\n",
    "        super(HaloToGalaxyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.fc3 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  \n",
    "        return x\n",
    "\n",
    "# Función para cargar datos desde un CSV\n",
    "def load_data_from_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, 5:10].values  \n",
    "    #y = data.iloc[:, 12:16].values  \n",
    "    y = data.iloc[:, 12].values  #esto sólo carga la masa, la gracia es que para cada modelo usar un única columa\n",
    "    return X, y\n",
    "\n",
    "\n",
    "class customLossYan(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super(customLossYan, self).__init__()\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        losses = []\n",
    "        for i,q in enumerate(self.quantiles):\n",
    "            #print(\"predicción: \",y_pred)\n",
    "            #print(\"verdad: \",y_true)\n",
    "            errors = y_true[:,i] - y_pred[:,i]\n",
    "            losses.append(\n",
    "                torch.max((q - 1) * errors, q * errors)\n",
    "            )\n",
    "        loss = torch.mean(torch.stack(losses).sum(dim=0))\n",
    "        return loss           \n",
    "\n",
    "\n",
    "def ks_test_metric(y_true, y_pred):    \n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = torch.argmax(y_pred, dim=1).cpu().numpy()\n",
    "    \n",
    "    ks_statistic, p_value = ks_2samp(y_true, y_pred)\n",
    "    return ks_statistic, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e59c21d-8574-495f-a112-361179d3a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "file_path = 'datasetcompleto.csv'  \n",
    "X, y = load_data_from_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70941a9c-b5bc-4470-831e-585d6300581c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "k = 50 #división de bins, 50 es lo que dice el paper\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81f884e-ff8a-43cb-afae-b30561606814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transformar etiquetas a bins para problema de clasificacion\n",
    "#bins = np.linspace(y.min(), y.max(), k )\n",
    "#y_binned = np.digitize(y, bins) - 1\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "y = y.expand(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92256f18-55ea-4f02-a2c6-79a3230157f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.7251, 12.7251, 12.7251],\n",
      "        [12.5769, 12.5769, 12.5769],\n",
      "        [12.5146, 12.5146, 12.5146],\n",
      "        ...,\n",
      "        [ 8.8070,  8.8070,  8.8070],\n",
      "        [ 8.8324,  8.8324,  8.8324],\n",
      "        [ 8.7774,  8.7774,  8.7774]])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640916ef-c3fa-412d-987b-8678329b529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.4, random_state=69)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.12, random_state=69)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "hidden_dim = 100 #tamaño de las capas ocultas\n",
    "num_epochs = 1000\n",
    "early_stop_patience = 30\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "quantiles = [0.25, 0.5, 0.75] \n",
    "\n",
    "model = HaloToGalaxyModel(X.shape[1], len(quantiles), hidden_dim).to(device)\n",
    "#model.load_state_dict(torch.load('halo_to_galaxy_model3cuantiles.pth'))\n",
    "#quantiles = np.linspace(0, 1, 50)[1:-1]  # Excluir 0 y 1\n",
    "\n",
    "criterion = customLossYan(quantiles)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b03317-40f0-4d2e-aec4-b14fe723377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.2701, 10.2701, 10.2701],\n",
      "        [ 9.0961,  9.0961,  9.0961],\n",
      "        [ 9.6167,  9.6167,  9.6167],\n",
      "        ...,\n",
      "        [ 9.0848,  9.0848,  9.0848],\n",
      "        [ 9.2516,  9.2516,  9.2516],\n",
      "        [ 9.9465,  9.9465,  9.9465]])\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde7701a-1bdc-43d2-9581-880cf81264ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.3156, Val Loss: 0.2523, Val Accuracy: 0.0000\n",
      "Epoch [2/1000], Loss: 0.2184, Val Loss: 0.2042, Val Accuracy: 0.0000\n",
      "Epoch [3/1000], Loss: 0.2043, Val Loss: 0.1755, Val Accuracy: 0.0000\n",
      "Epoch [4/1000], Loss: 0.1970, Val Loss: 0.1755, Val Accuracy: 0.0000\n",
      "Epoch [5/1000], Loss: 0.1938, Val Loss: 0.1690, Val Accuracy: 0.0000\n",
      "Epoch [6/1000], Loss: 0.1911, Val Loss: 0.1757, Val Accuracy: 0.0000\n",
      "Epoch [7/1000], Loss: 0.1855, Val Loss: 0.2022, Val Accuracy: 0.0000\n",
      "Epoch [8/1000], Loss: 0.1834, Val Loss: 0.2010, Val Accuracy: 0.0000\n",
      "Epoch [9/1000], Loss: 0.1816, Val Loss: 0.1637, Val Accuracy: 0.0000\n",
      "Epoch [10/1000], Loss: 0.1789, Val Loss: 0.1673, Val Accuracy: 0.0000\n",
      "Epoch [11/1000], Loss: 0.1753, Val Loss: 0.1621, Val Accuracy: 0.0000\n",
      "Epoch [12/1000], Loss: 0.1737, Val Loss: 0.1521, Val Accuracy: 0.0000\n",
      "Epoch [13/1000], Loss: 0.1699, Val Loss: 0.1563, Val Accuracy: 0.0000\n",
      "Epoch [14/1000], Loss: 0.1675, Val Loss: 0.1689, Val Accuracy: 0.0000\n",
      "Epoch [15/1000], Loss: 0.1665, Val Loss: 0.1572, Val Accuracy: 0.0000\n",
      "Epoch [16/1000], Loss: 0.1649, Val Loss: 0.1609, Val Accuracy: 0.0000\n",
      "Epoch [17/1000], Loss: 0.1638, Val Loss: 0.1517, Val Accuracy: 0.0000\n",
      "Epoch [18/1000], Loss: 0.1622, Val Loss: 0.1601, Val Accuracy: 0.0000\n",
      "Epoch [19/1000], Loss: 0.1621, Val Loss: 0.1489, Val Accuracy: 0.0000\n",
      "Epoch [20/1000], Loss: 0.1628, Val Loss: 0.1451, Val Accuracy: 0.0000\n",
      "Epoch [21/1000], Loss: 0.1620, Val Loss: 0.1474, Val Accuracy: 0.0000\n",
      "Epoch [22/1000], Loss: 0.1611, Val Loss: 0.1454, Val Accuracy: 0.0000\n",
      "Epoch [23/1000], Loss: 0.1603, Val Loss: 0.1553, Val Accuracy: 0.0000\n",
      "Epoch [24/1000], Loss: 0.1607, Val Loss: 0.1523, Val Accuracy: 0.0000\n",
      "Epoch [25/1000], Loss: 0.1596, Val Loss: 0.1479, Val Accuracy: 0.0000\n",
      "Epoch [26/1000], Loss: 0.1603, Val Loss: 0.1701, Val Accuracy: 0.0000\n",
      "Epoch [27/1000], Loss: 0.1593, Val Loss: 0.1676, Val Accuracy: 0.0000\n",
      "Epoch [28/1000], Loss: 0.1587, Val Loss: 0.1672, Val Accuracy: 0.0000\n",
      "Epoch [29/1000], Loss: 0.1583, Val Loss: 0.1510, Val Accuracy: 0.0000\n",
      "Epoch [30/1000], Loss: 0.1595, Val Loss: 0.1512, Val Accuracy: 0.0000\n",
      "Epoch [31/1000], Loss: 0.1593, Val Loss: 0.1482, Val Accuracy: 0.0000\n",
      "Epoch [32/1000], Loss: 0.1578, Val Loss: 0.1440, Val Accuracy: 0.0000\n",
      "Epoch [33/1000], Loss: 0.1578, Val Loss: 0.1447, Val Accuracy: 0.0000\n",
      "Epoch [34/1000], Loss: 0.1576, Val Loss: 0.1445, Val Accuracy: 0.0000\n",
      "Epoch [35/1000], Loss: 0.1566, Val Loss: 0.1578, Val Accuracy: 0.0000\n",
      "Epoch [36/1000], Loss: 0.1567, Val Loss: 0.1424, Val Accuracy: 0.0000\n",
      "Epoch [37/1000], Loss: 0.1558, Val Loss: 0.1640, Val Accuracy: 0.0000\n",
      "Epoch [38/1000], Loss: 0.1557, Val Loss: 0.1533, Val Accuracy: 0.0000\n",
      "Epoch [39/1000], Loss: 0.1552, Val Loss: 0.1410, Val Accuracy: 0.0000\n",
      "Epoch [40/1000], Loss: 0.1544, Val Loss: 0.1474, Val Accuracy: 0.0000\n",
      "Epoch [41/1000], Loss: 0.1536, Val Loss: 0.1392, Val Accuracy: 0.0000\n",
      "Epoch [42/1000], Loss: 0.1528, Val Loss: 0.1546, Val Accuracy: 0.0000\n",
      "Epoch [43/1000], Loss: 0.1527, Val Loss: 0.1385, Val Accuracy: 0.0000\n",
      "Epoch [44/1000], Loss: 0.1524, Val Loss: 0.1439, Val Accuracy: 0.0000\n",
      "Epoch [45/1000], Loss: 0.1523, Val Loss: 0.1769, Val Accuracy: 0.0000\n",
      "Epoch [46/1000], Loss: 0.1519, Val Loss: 0.1761, Val Accuracy: 0.0000\n",
      "Epoch [47/1000], Loss: 0.1512, Val Loss: 0.1862, Val Accuracy: 0.0000\n",
      "Epoch [48/1000], Loss: 0.1512, Val Loss: 0.1375, Val Accuracy: 0.0000\n",
      "Epoch [49/1000], Loss: 0.1502, Val Loss: 0.1658, Val Accuracy: 0.0000\n",
      "Epoch [50/1000], Loss: 0.1503, Val Loss: 0.1510, Val Accuracy: 0.0000\n",
      "Epoch [51/1000], Loss: 0.1500, Val Loss: 0.1542, Val Accuracy: 0.0000\n",
      "Epoch [52/1000], Loss: 0.1501, Val Loss: 0.1356, Val Accuracy: 0.0000\n",
      "Epoch [53/1000], Loss: 0.1498, Val Loss: 0.1480, Val Accuracy: 0.0000\n",
      "Epoch [54/1000], Loss: 0.1492, Val Loss: 0.1403, Val Accuracy: 0.0000\n",
      "Epoch [55/1000], Loss: 0.1498, Val Loss: 0.1523, Val Accuracy: 0.0000\n",
      "Epoch [56/1000], Loss: 0.1490, Val Loss: 0.2100, Val Accuracy: 0.0000\n",
      "Epoch [57/1000], Loss: 0.1487, Val Loss: 0.1395, Val Accuracy: 0.0000\n",
      "Epoch [58/1000], Loss: 0.1480, Val Loss: 0.1596, Val Accuracy: 0.0000\n",
      "Epoch [59/1000], Loss: 0.1487, Val Loss: 0.1410, Val Accuracy: 0.0000\n",
      "Epoch [60/1000], Loss: 0.1486, Val Loss: 0.1440, Val Accuracy: 0.0000\n",
      "Epoch [61/1000], Loss: 0.1481, Val Loss: 0.1363, Val Accuracy: 0.0000\n",
      "Epoch [62/1000], Loss: 0.1481, Val Loss: 0.1373, Val Accuracy: 0.0000\n",
      "Epoch [63/1000], Loss: 0.1480, Val Loss: 0.1359, Val Accuracy: 0.0000\n",
      "Epoch [64/1000], Loss: 0.1488, Val Loss: 0.1389, Val Accuracy: 0.0000\n",
      "Epoch [65/1000], Loss: 0.1479, Val Loss: 0.1410, Val Accuracy: 0.0000\n",
      "Epoch [66/1000], Loss: 0.1474, Val Loss: 0.1531, Val Accuracy: 0.0000\n",
      "Epoch [67/1000], Loss: 0.1478, Val Loss: 0.1395, Val Accuracy: 0.0000\n",
      "Epoch [68/1000], Loss: 0.1470, Val Loss: 0.1425, Val Accuracy: 0.0000\n",
      "Epoch [69/1000], Loss: 0.1474, Val Loss: 0.1419, Val Accuracy: 0.0000\n",
      "Epoch [70/1000], Loss: 0.1473, Val Loss: 0.1387, Val Accuracy: 0.0000\n",
      "Epoch [71/1000], Loss: 0.1471, Val Loss: 0.1348, Val Accuracy: 0.0000\n",
      "Epoch [72/1000], Loss: 0.1467, Val Loss: 0.1372, Val Accuracy: 0.0000\n",
      "Epoch [73/1000], Loss: 0.1466, Val Loss: 0.1660, Val Accuracy: 0.0000\n",
      "Epoch [74/1000], Loss: 0.1470, Val Loss: 0.1468, Val Accuracy: 0.0000\n",
      "Epoch [75/1000], Loss: 0.1467, Val Loss: 0.1517, Val Accuracy: 0.0000\n",
      "Epoch [76/1000], Loss: 0.1469, Val Loss: 0.1361, Val Accuracy: 0.0000\n",
      "Epoch [77/1000], Loss: 0.1465, Val Loss: 0.1338, Val Accuracy: 0.0000\n",
      "Epoch [78/1000], Loss: 0.1462, Val Loss: 0.1558, Val Accuracy: 0.0000\n",
      "Epoch [79/1000], Loss: 0.1464, Val Loss: 0.1383, Val Accuracy: 0.0000\n",
      "Epoch [80/1000], Loss: 0.1464, Val Loss: 0.1384, Val Accuracy: 0.0000\n",
      "Epoch [81/1000], Loss: 0.1460, Val Loss: 0.1393, Val Accuracy: 0.0000\n",
      "Epoch [82/1000], Loss: 0.1461, Val Loss: 0.1438, Val Accuracy: 0.0000\n",
      "Epoch [83/1000], Loss: 0.1460, Val Loss: 0.1396, Val Accuracy: 0.0000\n",
      "Epoch [84/1000], Loss: 0.1459, Val Loss: 0.1575, Val Accuracy: 0.0000\n",
      "Epoch [85/1000], Loss: 0.1460, Val Loss: 0.1540, Val Accuracy: 0.0000\n",
      "Epoch [86/1000], Loss: 0.1458, Val Loss: 0.1433, Val Accuracy: 0.0000\n",
      "Epoch [87/1000], Loss: 0.1452, Val Loss: 0.1370, Val Accuracy: 0.0000\n",
      "Epoch [88/1000], Loss: 0.1452, Val Loss: 0.1362, Val Accuracy: 0.0000\n",
      "Epoch [89/1000], Loss: 0.1456, Val Loss: 0.1373, Val Accuracy: 0.0000\n",
      "Epoch [90/1000], Loss: 0.1453, Val Loss: 0.1507, Val Accuracy: 0.0000\n",
      "Epoch [91/1000], Loss: 0.1448, Val Loss: 0.1662, Val Accuracy: 0.0000\n",
      "Epoch [92/1000], Loss: 0.1448, Val Loss: 0.1474, Val Accuracy: 0.0000\n",
      "Epoch [93/1000], Loss: 0.1443, Val Loss: 0.1420, Val Accuracy: 0.0000\n",
      "Epoch [94/1000], Loss: 0.1445, Val Loss: 0.1405, Val Accuracy: 0.0000\n",
      "Epoch [95/1000], Loss: 0.1438, Val Loss: 0.1340, Val Accuracy: 0.0000\n",
      "Epoch [96/1000], Loss: 0.1443, Val Loss: 0.1515, Val Accuracy: 0.0000\n",
      "Epoch [97/1000], Loss: 0.1438, Val Loss: 0.1503, Val Accuracy: 0.0000\n",
      "Epoch [98/1000], Loss: 0.1436, Val Loss: 0.1354, Val Accuracy: 0.0000\n",
      "Epoch [99/1000], Loss: 0.1434, Val Loss: 0.1370, Val Accuracy: 0.0000\n",
      "Epoch [100/1000], Loss: 0.1435, Val Loss: 0.1675, Val Accuracy: 0.0000\n",
      "Epoch [101/1000], Loss: 0.1437, Val Loss: 0.1361, Val Accuracy: 0.0000\n",
      "Epoch [102/1000], Loss: 0.1435, Val Loss: 0.1342, Val Accuracy: 0.0000\n",
      "Epoch [103/1000], Loss: 0.1433, Val Loss: 0.1424, Val Accuracy: 0.0000\n",
      "Epoch [104/1000], Loss: 0.1427, Val Loss: 0.1372, Val Accuracy: 0.0000\n",
      "Epoch [105/1000], Loss: 0.1434, Val Loss: 0.1465, Val Accuracy: 0.0000\n",
      "Epoch [106/1000], Loss: 0.1430, Val Loss: 0.1483, Val Accuracy: 0.0000\n",
      "Epoch [107/1000], Loss: 0.1431, Val Loss: 0.1357, Val Accuracy: 0.0000\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(targets, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(targets, outputs)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = torch.round(outputs)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'halo_to_galaxy_model3cuantiles.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == early_stop_patience:\n",
    "            print('Early stopping!')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f084434b-d31d-44ef-a785-72499bbb70e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1350, Test Accuracy: 0.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Array shapes are incompatible for broadcasting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m y_test_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(y_test_all)\n\u001b[0;32m     32\u001b[0m outputs_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(outputs_all)\n\u001b[1;32m---> 33\u001b[0m ks_statistic, p_value \u001b[38;5;241m=\u001b[39m \u001b[43mks_test_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_all\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_all\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKS Statistic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mks_statistic\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, P-value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 46\u001b[0m, in \u001b[0;36mks_test_metric\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     43\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     44\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 46\u001b[0m ks_statistic, p_value \u001b[38;5;241m=\u001b[39m \u001b[43mks_2samp\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ks_statistic, p_value\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:483\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    481\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(sample\u001b[38;5;241m.\u001b[39mravel()) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(axis)\n\u001b[0;32m    485\u001b[0m     n_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:18\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[1;34m(arrays, axis)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_arrays\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    Broadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_array_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m         new_shapes \u001b[38;5;241m=\u001b[39m [new_shapes]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrays)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:30\u001b[0m, in \u001b[0;36m_broadcast_array_shapes\u001b[1;34m(arrays, axis)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mBroadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(arr)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:81\u001b[0m, in \u001b[0;36m_broadcast_shapes\u001b[1;34m(shapes, axis)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Among all arrays, there can only be one unique non-1 shape element.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Therefore, if any non-1 shape element does not match what we found\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# above, the arrays must not be broadcastable after all.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;241m~\u001b[39m((new_shapes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m|\u001b[39m (new_shapes \u001b[38;5;241m==\u001b[39m new_shape))):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray shapes are incompatible for broadcasting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Add back the shape elements that were ignored\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(axis))\n",
      "\u001b[1;31mValueError\u001b[0m: Array shapes are incompatible for broadcasting."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('halo_to_galaxy_model3cuantiles.pth'))\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(targets, outputs)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        predicted = torch.round(outputs)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "y_test_all = []\n",
    "outputs_all = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_test_all.append(targets.cpu().numpy())\n",
    "        outputs_all.append(outputs.cpu().numpy())\n",
    "\n",
    "y_test_all = np.concatenate(y_test_all)\n",
    "outputs_all = np.concatenate(outputs_all)\n",
    "ks_statistic, p_value = ks_test_metric(torch.tensor(y_test_all), torch.tensor(outputs_all))\n",
    "print(f'KS Statistic: {ks_statistic:.4f}, P-value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef1d10-fc0c-4fe3-ac33-52630492e867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
