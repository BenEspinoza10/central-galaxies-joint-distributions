{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9c311a-bbe3-4437-8853-8656eaafe19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac284d66-405a-4cf0-92a5-0642c2db9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura neuronal\n",
    "class HaloToGalaxyModel(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=1, hidden_dim=64):\n",
    "        super(HaloToGalaxyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.fc3 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  \n",
    "        return x\n",
    "\n",
    "# Función para cargar datos desde un CSV\n",
    "def load_data_from_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, 5:10].values  \n",
    "    #y = data.iloc[:, 12:16].values  \n",
    "    y = data.iloc[:, 12].values  #esto sólo carga la masa, la gracia es que para cada modelo usar un única columa\n",
    "    return X, y\n",
    "\n",
    "\n",
    "class customLossYan(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super(customLossYan, self).__init__()\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        #y_true_one_hot = F.one_hot(y_true, num_classes=y_pred.size(1)).float()\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            errors = y_true - y_pred[:, i]\n",
    "            losses.append(\n",
    "                torch.max((q - 1) * errors, q * errors).unsqueeze(1)\n",
    "            )\n",
    "        loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "        return loss\n",
    "\n",
    "\n",
    "def ks_test_metric(y_true, y_pred):    \n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = torch.argmax(y_pred, dim=1).cpu().numpy()\n",
    "    \n",
    "    ks_statistic, p_value = ks_2samp(y_true, y_pred)\n",
    "    return ks_statistic, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e59c21d-8574-495f-a112-361179d3a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "file_path = 'datasetcompleto.csv'  \n",
    "X, y = load_data_from_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70941a9c-b5bc-4470-831e-585d6300581c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "k = 50 #división de bins, 50 es lo que dice el paper\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81f884e-ff8a-43cb-afae-b30561606814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transformar etiquetas a bins para problema de clasificacion\n",
    "bins = np.linspace(y.min(), y.max(), k )\n",
    "y_binned = np.digitize(y, bins) - 1\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92256f18-55ea-4f02-a2c6-79a3230157f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174785\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640916ef-c3fa-412d-987b-8678329b529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.12, random_state=42)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "hidden_dim = 100 #tamaño de las capas ocultas\n",
    "num_epochs = 1000\n",
    "early_stop_patience = 30\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "model = HaloToGalaxyModel(X.shape[1], 3, hidden_dim).to(device)\n",
    "#model.load_state_dict(torch.load('halo_to_galaxy_model3cuantiles.pth'))\n",
    "#quantiles = np.linspace(0, 1, 50)[1:-1]  # Excluir 0 y 1\n",
    "quantiles = [0.25, 0.5, 0.75] \n",
    "criterion = customLossYan(quantiles)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b03317-40f0-4d2e-aec4-b14fe723377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.2895,  9.3304,  9.3432,  ...,  9.6249,  9.6279,  9.5978],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde7701a-1bdc-43d2-9581-880cf81264ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.1912, Val Loss: 0.2089\n",
      "Epoch [2/1000], Loss: 0.1959, Val Loss: 0.1955\n",
      "Epoch [3/1000], Loss: 0.1739, Val Loss: 0.2202\n",
      "Epoch [4/1000], Loss: 0.2777, Val Loss: 0.2454\n",
      "Epoch [5/1000], Loss: 0.2056, Val Loss: 0.2476\n",
      "Epoch [6/1000], Loss: 0.1662, Val Loss: 0.1888\n",
      "Epoch [7/1000], Loss: 0.2858, Val Loss: 0.2623\n",
      "Epoch [8/1000], Loss: 0.2873, Val Loss: 0.2649\n",
      "Epoch [9/1000], Loss: 0.2021, Val Loss: 0.1958\n",
      "Epoch [10/1000], Loss: 0.1875, Val Loss: 0.1987\n",
      "Epoch [11/1000], Loss: 0.2914, Val Loss: 0.2523\n",
      "Epoch [12/1000], Loss: 0.1864, Val Loss: 0.1997\n",
      "Epoch [13/1000], Loss: 0.2048, Val Loss: 0.1908\n",
      "Epoch [14/1000], Loss: 0.1849, Val Loss: 0.2010\n",
      "Epoch [15/1000], Loss: 0.2375, Val Loss: 0.2263\n",
      "Epoch [16/1000], Loss: 0.1744, Val Loss: 0.1900\n",
      "Epoch [17/1000], Loss: 0.1917, Val Loss: 0.2091\n",
      "Epoch [18/1000], Loss: 0.1914, Val Loss: 0.2199\n",
      "Epoch [19/1000], Loss: 0.2018, Val Loss: 0.1972\n",
      "Epoch [20/1000], Loss: 0.2085, Val Loss: 0.1909\n",
      "Epoch [21/1000], Loss: 0.2055, Val Loss: 0.2007\n",
      "Epoch [22/1000], Loss: 0.1945, Val Loss: 0.2015\n",
      "Epoch [23/1000], Loss: 0.1853, Val Loss: 0.1860\n",
      "Epoch [24/1000], Loss: 0.1816, Val Loss: 0.1868\n",
      "Epoch [25/1000], Loss: 0.3010, Val Loss: 0.2611\n",
      "Epoch [26/1000], Loss: 0.1841, Val Loss: 0.1891\n",
      "Epoch [27/1000], Loss: 0.1719, Val Loss: 0.1890\n",
      "Epoch [28/1000], Loss: 0.2016, Val Loss: 0.2007\n",
      "Epoch [29/1000], Loss: 0.1743, Val Loss: 0.1924\n",
      "Epoch [30/1000], Loss: 0.1748, Val Loss: 0.1914\n",
      "Epoch [31/1000], Loss: 0.1740, Val Loss: 0.1929\n",
      "Epoch [32/1000], Loss: 0.1860, Val Loss: 0.1957\n",
      "Epoch [33/1000], Loss: 0.2637, Val Loss: 0.2325\n",
      "Epoch [34/1000], Loss: 0.1761, Val Loss: 0.1891\n",
      "Epoch [35/1000], Loss: 0.2073, Val Loss: 0.2001\n",
      "Epoch [36/1000], Loss: 0.1957, Val Loss: 0.1906\n",
      "Epoch [37/1000], Loss: 0.2151, Val Loss: 0.2033\n",
      "Epoch [38/1000], Loss: 0.2694, Val Loss: 0.2373\n",
      "Epoch [39/1000], Loss: 0.1989, Val Loss: 0.2220\n",
      "Epoch [40/1000], Loss: 0.2135, Val Loss: 0.2003\n",
      "Epoch [41/1000], Loss: 0.2293, Val Loss: 0.2130\n",
      "Epoch [42/1000], Loss: 0.1919, Val Loss: 0.2334\n",
      "Epoch [43/1000], Loss: 0.2013, Val Loss: 0.2013\n",
      "Epoch [44/1000], Loss: 0.1931, Val Loss: 0.1906\n",
      "Epoch [45/1000], Loss: 0.2216, Val Loss: 0.2478\n",
      "Epoch [46/1000], Loss: 0.1808, Val Loss: 0.1921\n",
      "Epoch [47/1000], Loss: 0.1770, Val Loss: 0.1874\n",
      "Epoch [48/1000], Loss: 0.1758, Val Loss: 0.1870\n",
      "Epoch [49/1000], Loss: 0.2439, Val Loss: 0.2153\n",
      "Epoch [50/1000], Loss: 0.1601, Val Loss: 0.1874\n",
      "Epoch [51/1000], Loss: 0.1851, Val Loss: 0.1842\n",
      "Epoch [52/1000], Loss: 0.2114, Val Loss: 0.1926\n",
      "Epoch [53/1000], Loss: 0.1861, Val Loss: 0.1960\n",
      "Epoch [54/1000], Loss: 0.2049, Val Loss: 0.1898\n",
      "Epoch [55/1000], Loss: 0.1759, Val Loss: 0.1876\n",
      "Epoch [56/1000], Loss: 0.2616, Val Loss: 0.2176\n",
      "Epoch [57/1000], Loss: 0.1879, Val Loss: 0.1889\n",
      "Epoch [58/1000], Loss: 0.2218, Val Loss: 0.1896\n",
      "Epoch [59/1000], Loss: 0.2413, Val Loss: 0.2074\n",
      "Epoch [60/1000], Loss: 0.1743, Val Loss: 0.1907\n",
      "Epoch [61/1000], Loss: 0.1958, Val Loss: 0.1945\n",
      "Epoch [62/1000], Loss: 0.1667, Val Loss: 0.1868\n",
      "Epoch [63/1000], Loss: 0.2078, Val Loss: 0.1881\n",
      "Epoch [64/1000], Loss: 0.1663, Val Loss: 0.2015\n",
      "Epoch [65/1000], Loss: 0.2572, Val Loss: 0.2187\n",
      "Epoch [66/1000], Loss: 0.1641, Val Loss: 0.1866\n",
      "Epoch [67/1000], Loss: 0.2025, Val Loss: 0.1908\n",
      "Epoch [68/1000], Loss: 0.2138, Val Loss: 0.1846\n",
      "Epoch [69/1000], Loss: 0.2022, Val Loss: 0.1956\n",
      "Epoch [70/1000], Loss: 0.1916, Val Loss: 0.1941\n",
      "Epoch [71/1000], Loss: 0.1785, Val Loss: 0.1693\n",
      "Epoch [72/1000], Loss: 0.1854, Val Loss: 0.2114\n",
      "Epoch [73/1000], Loss: 0.1284, Val Loss: 0.1638\n",
      "Epoch [74/1000], Loss: 0.1529, Val Loss: 0.1698\n",
      "Epoch [75/1000], Loss: 0.1692, Val Loss: 0.1656\n",
      "Epoch [76/1000], Loss: 0.1358, Val Loss: 0.1538\n",
      "Epoch [77/1000], Loss: 0.1566, Val Loss: 0.1841\n",
      "Epoch [78/1000], Loss: 0.1572, Val Loss: 0.1642\n",
      "Epoch [79/1000], Loss: 0.1341, Val Loss: 0.1535\n",
      "Epoch [80/1000], Loss: 0.1155, Val Loss: 0.1551\n",
      "Epoch [81/1000], Loss: 0.1961, Val Loss: 0.1771\n",
      "Epoch [82/1000], Loss: 0.1022, Val Loss: 0.1502\n",
      "Epoch [83/1000], Loss: 0.1652, Val Loss: 0.1617\n",
      "Epoch [84/1000], Loss: 0.1309, Val Loss: 0.1478\n",
      "Epoch [85/1000], Loss: 0.1714, Val Loss: 0.2104\n",
      "Epoch [86/1000], Loss: 0.1473, Val Loss: 0.1509\n",
      "Epoch [87/1000], Loss: 0.1197, Val Loss: 0.1468\n",
      "Epoch [88/1000], Loss: 0.1285, Val Loss: 0.1439\n",
      "Epoch [89/1000], Loss: 0.2692, Val Loss: 0.2266\n",
      "Epoch [90/1000], Loss: 0.1166, Val Loss: 0.1472\n",
      "Epoch [91/1000], Loss: 0.1491, Val Loss: 0.1552\n",
      "Epoch [92/1000], Loss: 0.1283, Val Loss: 0.1460\n",
      "Epoch [93/1000], Loss: 0.1170, Val Loss: 0.1428\n",
      "Epoch [94/1000], Loss: 0.1104, Val Loss: 0.1467\n",
      "Epoch [95/1000], Loss: 0.1176, Val Loss: 0.1462\n",
      "Epoch [96/1000], Loss: 0.1310, Val Loss: 0.1472\n",
      "Epoch [97/1000], Loss: 0.2017, Val Loss: 0.1863\n",
      "Epoch [98/1000], Loss: 0.1401, Val Loss: 0.1461\n",
      "Epoch [99/1000], Loss: 0.1069, Val Loss: 0.1466\n",
      "Epoch [100/1000], Loss: 0.1433, Val Loss: 0.1577\n",
      "Epoch [101/1000], Loss: 0.1657, Val Loss: 0.1981\n",
      "Epoch [102/1000], Loss: 0.1318, Val Loss: 0.1461\n",
      "Epoch [103/1000], Loss: 0.1031, Val Loss: 0.1557\n",
      "Epoch [104/1000], Loss: 0.1628, Val Loss: 0.1795\n",
      "Epoch [105/1000], Loss: 0.1327, Val Loss: 0.1771\n",
      "Epoch [106/1000], Loss: 0.1111, Val Loss: 0.1613\n",
      "Epoch [107/1000], Loss: 0.1544, Val Loss: 0.1639\n",
      "Epoch [108/1000], Loss: 0.1583, Val Loss: 0.1594\n",
      "Epoch [109/1000], Loss: 0.1093, Val Loss: 0.1434\n",
      "Epoch [110/1000], Loss: 0.1019, Val Loss: 0.1641\n",
      "Epoch [111/1000], Loss: 0.1673, Val Loss: 0.1585\n",
      "Epoch [112/1000], Loss: 0.0916, Val Loss: 0.1580\n",
      "Epoch [113/1000], Loss: 0.1128, Val Loss: 0.1520\n",
      "Epoch [114/1000], Loss: 0.2097, Val Loss: 0.1824\n",
      "Epoch [115/1000], Loss: 0.1529, Val Loss: 0.1645\n",
      "Epoch [116/1000], Loss: 0.1367, Val Loss: 0.1460\n",
      "Epoch [117/1000], Loss: 0.1206, Val Loss: 0.1572\n",
      "Epoch [118/1000], Loss: 0.2670, Val Loss: 0.2336\n",
      "Epoch [119/1000], Loss: 0.1654, Val Loss: 0.1524\n",
      "Epoch [120/1000], Loss: 0.1142, Val Loss: 0.1590\n",
      "Epoch [121/1000], Loss: 0.1271, Val Loss: 0.1429\n",
      "Epoch [122/1000], Loss: 0.1311, Val Loss: 0.1451\n",
      "Epoch [123/1000], Loss: 0.1252, Val Loss: 0.1487\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(targets, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)     \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(targets, outputs)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'halo_to_galaxy_model3cuantiles.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == early_stop_patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "torch.save(model.state_dict(), 'halo_to_galaxy_model3cuantiles.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f084434b-d31d-44ef-a785-72499bbb70e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Statistic: 1.0000, P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('halo_to_galaxy_model3cuantiles.pth'))\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "'''with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(targets, outputs)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calcular precisión\n",
    "        predicted = outputs.round()  # Redondear las predicciones para compararlas con las etiquetas\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "accuracy = correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}')'''\n",
    "\n",
    "# KS test\n",
    "y_test_all = []\n",
    "outputs_all = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_test_all.append(targets.cpu().numpy())\n",
    "        outputs_all.append(outputs.cpu().numpy())\n",
    "y_test_all = np.concatenate(y_test_all)\n",
    "outputs_all = np.concatenate(outputs_all)\n",
    "ks_statistic, p_value = ks_test_metric(torch.tensor(y_test_all), torch.tensor(outputs_all))\n",
    "print(f'KS Statistic: {ks_statistic:.4f}, P-value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef1d10-fc0c-4fe3-ac33-52630492e867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
