{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9c311a-bbe3-4437-8853-8656eaafe19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac284d66-405a-4cf0-92a5-0642c2db9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura neuronal\n",
    "class HaloToGalaxyModel(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=50, hidden_dim=64):\n",
    "        super(HaloToGalaxyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim)        \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  \n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "# Función para cargar datos desde un CSV\n",
    "def load_data_from_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, 5:10].values  \n",
    "    #y = data.iloc[:, 12:16].values  \n",
    "    y = data.iloc[:, 12].values  #esto sólo carga la masa, la gracia es que para cada modelo usar un única columa\n",
    "    return X, y\n",
    "\n",
    "\n",
    "class customLossYan(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super(customLossYan, self).__init__()\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        y_true_one_hot = F.one_hot(y_true, num_classes=y_pred.size(1)).float()\n",
    "        losses = []\n",
    "        for q in self.quantiles:\n",
    "            errors = y_true_one_hot - y_pred\n",
    "            losses.append(\n",
    "                torch.max((q - 1) * errors, q * errors)\n",
    "            )\n",
    "        loss = torch.mean(torch.sum(torch.stack(losses, dim=2), dim=2))\n",
    "        return loss\n",
    "\n",
    "\n",
    "def ks_test_metric(y_true, y_pred):\n",
    "    # Convertir a distribuciones acumuladas empíricas\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = torch.argmax(y_pred, dim=1).cpu().numpy()\n",
    "    \n",
    "    ks_statistic, p_value = ks_2samp(y_true, y_pred)\n",
    "    return ks_statistic, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e59c21d-8574-495f-a112-361179d3a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "file_path = 'datasetcompleto.csv'  \n",
    "X, y = load_data_from_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70941a9c-b5bc-4470-831e-585d6300581c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "k = 50 #división de bins, 50 es lo que dice el paper\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81f884e-ff8a-43cb-afae-b30561606814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transformar etiquetas a bins para problema de clasificacion\n",
    "bins = np.linspace(y.min(), y.max(), k + 1)\n",
    "y_binned = np.digitize(y, bins) - 1\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y_binned, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640916ef-c3fa-412d-987b-8678329b529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "hidden_dim = 100 #tamaño de las capas ocultas\n",
    "num_epochs = 1000\n",
    "early_stop_patience = 20\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "model = HaloToGalaxyModel(X.shape[1], k, hidden_dim).to(device)\n",
    "criterion = customLossYan(bins)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde7701a-1bdc-43d2-9581-880cf81264ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.9965, Val Loss: 0.9795\n",
      "Epoch [2/1000], Loss: 0.9791, Val Loss: 0.9718\n",
      "Epoch [3/1000], Loss: 0.9716, Val Loss: 0.9651\n",
      "Epoch [4/1000], Loss: 0.9652, Val Loss: 0.9615\n",
      "Epoch [5/1000], Loss: 0.9618, Val Loss: 0.9602\n",
      "Epoch [6/1000], Loss: 0.9604, Val Loss: 0.9595\n",
      "Epoch [7/1000], Loss: 0.9596, Val Loss: 0.9590\n",
      "Epoch [8/1000], Loss: 0.9589, Val Loss: 0.9583\n",
      "Epoch [9/1000], Loss: 0.9580, Val Loss: 0.9573\n",
      "Epoch [10/1000], Loss: 0.9568, Val Loss: 0.9560\n",
      "Epoch [11/1000], Loss: 0.9551, Val Loss: 0.9545\n",
      "Epoch [12/1000], Loss: 0.9535, Val Loss: 0.9539\n",
      "Epoch [13/1000], Loss: 0.9528, Val Loss: 0.9538\n",
      "Epoch [14/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [15/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [16/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [17/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [18/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [19/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [20/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [21/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [22/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [23/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [24/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [25/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [26/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [27/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [28/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [29/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [30/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [31/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [32/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [33/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [34/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [35/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [36/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [37/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Epoch [38/1000], Loss: 0.9526, Val Loss: 0.9537\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    optimizer.zero_grad() \n",
    "    outputs = model(X_train)     \n",
    "    loss = criterion(y_train,outputs)\n",
    "    loss.backward() \n",
    "    optimizer.step()     \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(y_val, val_outputs)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'halo_to_galaxy_model.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == early_stop_patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "torch.save(model.state_dict(), 'halo_to_galaxy_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f084434b-d31d-44ef-a785-72499bbb70e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 6.60%\n",
      "KS Statistic: 0.9340, P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('halo_to_galaxy_model.pth'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "    # KS test\n",
    "    ks_statistic, p_value = ks_test_metric(y_test, outputs)\n",
    "    print(f'KS Statistic: {ks_statistic:.4f}, P-value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef1d10-fc0c-4fe3-ac33-52630492e867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
