{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9c311a-bbe3-4437-8853-8656eaafe19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, median_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac284d66-405a-4cf0-92a5-0642c2db9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquitectura neuronal\n",
    "class HaloToGalaxyModel(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=1, hidden_dim=64):\n",
    "        super(HaloToGalaxyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.fc3 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  \n",
    "        return x\n",
    "\n",
    "# Función para cargar datos desde un CSV\n",
    "def load_data_from_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, 5:10].values  \n",
    "    #y = data.iloc[:, 12:16].values  \n",
    "    #y = data.iloc[:, 12].values  #esto sólo carga la masa,\n",
    "    #y = data.iloc[:, 13].values #color\n",
    "    #y = data.iloc[:, 14].values #radio\n",
    "    #y = data.iloc[:, 15].values #sSFR   \n",
    "    y1 = data.iloc[:, 13].values  #color,\n",
    "    y2 = data.iloc[:, 15].values #sSFR   \n",
    "    return X, y1,y2\n",
    "\n",
    "\n",
    "class customLossYan(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super(customLossYan, self).__init__()\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        losses = []\n",
    "        for i,q in enumerate(self.quantiles):\n",
    "            #print(\"predicción: \",y_pred)\n",
    "            #print(\"verdad: \",y_true)\n",
    "            errors = y_true[:,i] - y_pred[:,i]\n",
    "            losses.append(\n",
    "                torch.max((q - 1) * errors, q * errors)\n",
    "            )\n",
    "        loss = torch.mean(torch.stack(losses).sum(dim=0))\n",
    "        return loss           \n",
    "\n",
    "\n",
    "def quantile_loss(y_true, y_pred, quantiles):\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = y_true[:, i] - y_pred[:, i]\n",
    "        losses.append(np.maximum((q - 1) * errors, q * errors))\n",
    "    loss = np.mean(np.stack(losses).sum(axis=0))\n",
    "    return loss\n",
    "\n",
    "def coverage_probability(y_true, y_pred, quantiles):\n",
    "    coverage = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        coverage.append(np.mean((y_true[:, i] <= y_pred[:, i]) & (y_pred[:, i] <= y_true[:, i])))\n",
    "    return np.mean(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e59c21d-8574-495f-a112-361179d3a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "file_path = 'datasetcompleto.csv'  \n",
    "X, y1,y2 = load_data_from_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70941a9c-b5bc-4470-831e-585d6300581c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81f884e-ff8a-43cb-afae-b30561606814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y1 = torch.tensor(y1, dtype=torch.float32).unsqueeze(1)\n",
    "y2 = torch.tensor(y2, dtype=torch.float32).unsqueeze(1)\n",
    "y1 = y1.repeat(1, 3)\n",
    "y2 = y2.repeat(1, 3)\n",
    "\n",
    "# Concatenar los dos tensores a lo largo de la segunda dimensión\n",
    "y = torch.cat((y1, y2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92256f18-55ea-4f02-a2c6-79a3230157f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.1002,   1.1002,   1.1002, -13.6158, -13.6158, -13.6158],\n",
      "        [  1.0834,   1.0834,   1.0834, -12.5470, -12.5470, -12.5470],\n",
      "        [  0.9506,   0.9506,   0.9506, -11.6729, -11.6729, -11.6729],\n",
      "        ...,\n",
      "        [  1.0424,   1.0424,   1.0424, -13.4485, -13.4485, -13.4485],\n",
      "        [  1.0193,   1.0193,   1.0193, -13.0122, -13.0122, -13.0122],\n",
      "        [  0.9831,   0.9831,   0.9831, -13.6909, -13.6909, -13.6909]])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640916ef-c3fa-412d-987b-8678329b529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=69)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, random_state=69)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "hidden_dim = 100 #tamaño de las capas ocultas\n",
    "num_epochs = 1000\n",
    "early_stop_patience = 20\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "quantiles = [0.25, 0.5, 0.75,0.25, 0.5, 0.75] \n",
    "\n",
    "\n",
    "modelfile = 'colorysSFR.pth'\n",
    "model = HaloToGalaxyModel(X.shape[1], len(quantiles), hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load(modelfile))\n",
    "#quantiles = np.linspace(0, 1, 50)[1:-1]  # Excluir 0 y 1\n",
    "\n",
    "criterion = customLossYan(quantiles)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b03317-40f0-4d2e-aec4-b14fe723377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.6808,   0.6808,   0.6808, -10.0063, -10.0063, -10.0063],\n",
      "        [  0.5005,   0.5005,   0.5005,  -9.5698,  -9.5698,  -9.5698],\n",
      "        [  0.6943,   0.6943,   0.6943,  -9.7549,  -9.7549,  -9.7549],\n",
      "        ...,\n",
      "        [  1.1777,   1.1777,   1.1777, -14.2123, -14.2123, -14.2123],\n",
      "        [  0.8678,   0.8678,   0.8678,  -9.6318,  -9.6318,  -9.6318],\n",
      "        [  1.1048,   1.1048,   1.1048, -14.1196, -14.1196, -14.1196]])\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde7701a-1bdc-43d2-9581-880cf81264ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 1.4706, Val Loss: 1.1937\n",
      "Epoch [2/1000], Loss: 1.1933, Val Loss: 1.1748\n",
      "Epoch [3/1000], Loss: 1.1764, Val Loss: 1.1567\n",
      "Epoch [4/1000], Loss: 1.1569, Val Loss: 1.1398\n",
      "Epoch [5/1000], Loss: 1.1383, Val Loss: 1.1188\n",
      "Epoch [6/1000], Loss: 1.1211, Val Loss: 1.1040\n",
      "Epoch [7/1000], Loss: 1.1060, Val Loss: 1.1189\n",
      "Epoch [8/1000], Loss: 1.0926, Val Loss: 1.0795\n",
      "Epoch [9/1000], Loss: 1.0802, Val Loss: 1.0707\n",
      "Epoch [10/1000], Loss: 1.0704, Val Loss: 1.0551\n",
      "Epoch [11/1000], Loss: 1.0609, Val Loss: 1.0497\n",
      "Epoch [12/1000], Loss: 1.0527, Val Loss: 1.0340\n",
      "Epoch [13/1000], Loss: 1.0462, Val Loss: 1.0406\n",
      "Epoch [14/1000], Loss: 1.0393, Val Loss: 1.0271\n",
      "Epoch [15/1000], Loss: 1.0321, Val Loss: 1.0264\n",
      "Epoch [16/1000], Loss: 1.0263, Val Loss: 1.0214\n",
      "Epoch [17/1000], Loss: 1.0188, Val Loss: 0.9990\n",
      "Epoch [18/1000], Loss: 1.0125, Val Loss: 0.9998\n",
      "Epoch [19/1000], Loss: 1.0047, Val Loss: 1.0043\n",
      "Epoch [20/1000], Loss: 0.9992, Val Loss: 0.9836\n",
      "Epoch [21/1000], Loss: 0.9917, Val Loss: 0.9735\n",
      "Epoch [22/1000], Loss: 0.9858, Val Loss: 0.9714\n",
      "Epoch [23/1000], Loss: 0.9807, Val Loss: 0.9654\n",
      "Epoch [24/1000], Loss: 0.9742, Val Loss: 0.9572\n",
      "Epoch [25/1000], Loss: 0.9697, Val Loss: 0.9544\n",
      "Epoch [26/1000], Loss: 0.9650, Val Loss: 0.9538\n",
      "Epoch [27/1000], Loss: 0.9595, Val Loss: 0.9481\n",
      "Epoch [28/1000], Loss: 0.9544, Val Loss: 0.9413\n",
      "Epoch [29/1000], Loss: 0.9500, Val Loss: 0.9665\n",
      "Epoch [30/1000], Loss: 0.9459, Val Loss: 0.9479\n",
      "Epoch [31/1000], Loss: 0.9414, Val Loss: 0.9298\n",
      "Epoch [32/1000], Loss: 0.9382, Val Loss: 0.9263\n",
      "Epoch [33/1000], Loss: 0.9336, Val Loss: 0.9199\n",
      "Epoch [34/1000], Loss: 0.9298, Val Loss: 0.9357\n",
      "Epoch [35/1000], Loss: 0.9267, Val Loss: 0.9097\n",
      "Epoch [36/1000], Loss: 0.9218, Val Loss: 0.9101\n",
      "Epoch [37/1000], Loss: 0.9188, Val Loss: 0.9415\n",
      "Epoch [38/1000], Loss: 0.9160, Val Loss: 0.9027\n",
      "Epoch [39/1000], Loss: 0.9128, Val Loss: 0.9023\n",
      "Epoch [40/1000], Loss: 0.9102, Val Loss: 0.8975\n",
      "Epoch [41/1000], Loss: 0.9074, Val Loss: 0.8976\n",
      "Epoch [42/1000], Loss: 0.9054, Val Loss: 0.9239\n",
      "Epoch [43/1000], Loss: 0.9039, Val Loss: 0.9469\n",
      "Epoch [44/1000], Loss: 0.9018, Val Loss: 0.8899\n",
      "Epoch [45/1000], Loss: 0.9001, Val Loss: 0.8917\n",
      "Epoch [46/1000], Loss: 0.8983, Val Loss: 0.8863\n",
      "Epoch [47/1000], Loss: 0.8973, Val Loss: 0.8870\n",
      "Epoch [48/1000], Loss: 0.8950, Val Loss: 0.8890\n",
      "Epoch [49/1000], Loss: 0.8935, Val Loss: 0.9000\n",
      "Epoch [50/1000], Loss: 0.8927, Val Loss: 0.8884\n",
      "Epoch [51/1000], Loss: 0.8915, Val Loss: 0.8930\n",
      "Epoch [52/1000], Loss: 0.8902, Val Loss: 0.8954\n",
      "Epoch [53/1000], Loss: 0.8885, Val Loss: 0.8907\n",
      "Epoch [54/1000], Loss: 0.8881, Val Loss: 0.8939\n",
      "Epoch [55/1000], Loss: 0.8870, Val Loss: 0.8768\n",
      "Epoch [56/1000], Loss: 0.8849, Val Loss: 0.8899\n",
      "Epoch [57/1000], Loss: 0.8848, Val Loss: 0.8874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(targets, outputs)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(targets, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(targets, outputs)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "                        \n",
    "    val_loss /= len(val_loader.dataset)    \n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), modelfile)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == early_stop_patience:\n",
    "            print('Early stopping!')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084434b-d31d-44ef-a785-72499bbb70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(modelfile))\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "y_test_all = []\n",
    "outputs_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(targets, outputs)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        y_test_all.append(targets.cpu().numpy())\n",
    "        outputs_all.append(outputs.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "y_test_all = np.concatenate(y_test_all)\n",
    "outputs_all = np.concatenate(outputs_all)\n",
    "\n",
    "mae = mean_absolute_error(y_test_all, outputs_all)\n",
    "rmse = np.sqrt(test_loss)\n",
    "r2 = r2_score(y_test_all, outputs_all)\n",
    "median_ae = median_absolute_error(y_test_all, outputs_all)\n",
    "mape = mean_absolute_percentage_error(y_test_all, outputs_all)\n",
    "q_loss = quantile_loss(y_test_all, outputs_all, quantiles)\n",
    "coverage = coverage_probability(y_test_all, outputs_all, quantiles)\n",
    "#ks_statistic, p_value = ks_test_metric(torch.tensor(y_test_all), torch.tensor(outputs_all))\n",
    "\n",
    "print(f'Test Loss (MSE): {test_loss:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R²: {r2:.4f}')\n",
    "print(f'Median Absolute Error: {median_ae:.4f}')\n",
    "print(f'MAPE: {mape:.4f}')\n",
    "print(f'Quantile Loss: {q_loss:.4f}')\n",
    "print(f'Coverage Probability: {coverage:.4f}')\n",
    "#print(f'KS Statistic: {ks_statistic:.4f}, P-value: {p_value:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef1d10-fc0c-4fe3-ac33-52630492e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[9906])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54d997-c213-4ea6-a357-62fa44d5eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "experimento = model(X[9906])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274f8f7-d7de-4080-9269-cd895ebe1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd63d0a-e0e1-444d-91f7-fe2e5ae50e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
