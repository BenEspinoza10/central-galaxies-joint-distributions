{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nbodykit.lab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nbodykit import setup_logging\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.read_csv('../data/datasetcompleto.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" # Primero, dividimos en 60% (48% + 12%) y 40%\n",
    "train_and_val, test = train_test_split(data, test_size=0.4, random_state=42)\n",
    "\n",
    "# Ahora, dividimos el 60% en 48% y 12%\n",
    "train, val = train_test_split(train_and_val, test_size=0.2, random_state=42)  # 0.2 * 60% = 12% \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aux func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para cargar datos desde un CSV\n",
    "def load_data_from_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, 5:10].values\n",
    "    #y = data.iloc[:, 12:16].values\n",
    "    y = data.iloc[:, 12:14].values  #esto sólo carga el color\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class QuantileLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantileLoss, self).__init__()\n",
    "\n",
    "    def forward(self, yhat, y, tau):\n",
    "        diff = yhat - y\n",
    "        mask = (diff.ge(0).float() - tau).detach()\n",
    "        return (mask * diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto de abajo es mio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLossYan(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super(customLossYan, self).__init__()\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        losses = []\n",
    "        for i,q in enumerate(self.quantiles):\n",
    "            #print(\"predicción: \",y_pred)\n",
    "            #print(\"verdad: \",y_true)\n",
    "            errors = y_true[:,i] - y_pred[:,i]\n",
    "            losses.append(\n",
    "                torch.max((q - 1) * errors, q * errors)\n",
    "            )\n",
    "        loss = torch.mean(torch.stack(losses).sum(dim=0))\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x, tau=None):\n",
    "    if tau is None:\n",
    "        tau = torch.zeros(x.size(0), 1).fill_(0.5)\n",
    "    elif isinstance(tau, float):\n",
    "        tau = torch.zeros(x.size(0), 1).fill_(tau)\n",
    "    return torch.cat((x, (tau - 0.5) * 12), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'datasetcompleto.csv'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class aHaloToGalaxyModel(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=5, hidden_dim=64):\n",
    "        super(HaloToGalaxyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.ln2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es mio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaloToGalaxyModel(nn.Module):\n",
    "    def __init__(self, input_size=4, output_size=1, hidden_dim=64):\n",
    "        super(HaloToGalaxyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim) \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.fc3 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141353/341626595.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_smass.load_state_dict(torch.load('StellarMass.pth'))\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 5:10].values\n",
    "#y = data.iloc[:, 12:16].values\n",
    "y_smass = data.iloc[:, 12].values  #esto sólo carga la masa\n",
    "y_smass = torch.tensor(y_smass, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "y_smass = y_smass.repeat(1, 3)\n",
    "\n",
    "hidden_dim = 100 #tamaño de las capas ocultas\n",
    "\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "quantiles2 = [0.25, 0.5, 0.75,0.25, 0.5, 0.75]\n",
    "quantiles4 = [0.25, 0.5, 0.75,0.25, 0.5, 0.75,0.25, 0.5, 0.75,0.25, 0.5, 0.75]\n",
    "\n",
    "model_smass = HaloToGalaxyModel(X.shape[1], len(quantiles), hidden_dim).to(device)\n",
    "model_smass.load_state_dict(torch.load('StellarMass.pth'))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_smass.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "#optimizer.load_state_dict(torch.load('StellarMass.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141353/2548561704.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_smass_color.load_state_dict(torch.load('masaycolor.pth'))\n"
     ]
    }
   ],
   "source": [
    "y_color = data.iloc[:, 13].values  #esto sólo carga el color\n",
    "y_color = torch.tensor(y_color, dtype=torch.float32).unsqueeze(1)\n",
    "y_color = y_color.repeat(1,3)\n",
    "\n",
    "y_smass_color = torch.cat((y_smass, y_color), dim=1)\n",
    "\n",
    "model_smass_color = HaloToGalaxyModel(X.shape[1], len(quantiles2), hidden_dim).to(device)\n",
    "\n",
    "model_smass_color.load_state_dict(torch.load('masaycolor.pth'))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_smass_color.parameters(), lr=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141353/4169783595.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_color.load_state_dict(torch.load('color1.pth'))\n"
     ]
    }
   ],
   "source": [
    "model_color = HaloToGalaxyModel(X.shape[1], len(quantiles), hidden_dim).to(device)\n",
    "\n",
    "model_color.load_state_dict(torch.load('color1.pth'))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_color.parameters(), lr=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141353/3944336662.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_all.load_state_dict(torch.load('todos.pth'))\n"
     ]
    }
   ],
   "source": [
    "y_all = data.iloc[:, 12:16].values  #esto sólo carga la masa\n",
    "y_radio = data.iloc[:, 14].values #radio\n",
    "y_radio = torch.tensor(y_radio, dtype=torch.float32).unsqueeze(1)\n",
    "y_sSFR = data.iloc[:, 15].values #sSFR \n",
    "y_sSFR = torch.tensor(y_sSFR, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "y_radio = y_radio.repeat(1,3)\n",
    "y_sSFR = y_sSFR.repeat(1,3)\n",
    "\n",
    "y_all = torch.cat((y_smass, y_color,y_radio,y_sSFR),dim=1)\n",
    "\n",
    "model_all = HaloToGalaxyModel(X.shape[1], len(quantiles4), hidden_dim).to(device)\n",
    "\n",
    "model_all.load_state_dict(torch.load('todos.pth'))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_all.parameters(), lr=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev, test = train_test_split(data, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148567, 16), (26218, 16))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_smass = test.iloc[:, 12].values\\ny_smass = y_smass.reshape(-1, 1)\\ny_color = test.iloc[:, 13].values\\ny_color = y_color.reshape(-1, 1)\\ny_smass_color = test.iloc[:, 12:14].values\\ny_smass_color = y_smass_color.reshape(-2, 2)\\ny_all = test.iloc[:, 12:16].values\\ny_all = y_all.reshape(-4, 4)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.iloc[:, 5:10].values\n",
    "\n",
    "'''\n",
    "y_smass = test.iloc[:, 12].values\n",
    "y_smass = y_smass.reshape(-1, 1)\n",
    "y_color = test.iloc[:, 13].values\n",
    "y_color = y_color.reshape(-1, 1)\n",
    "y_smass_color = test.iloc[:, 12:14].values\n",
    "y_smass_color = y_smass_color.reshape(-2, 2)\n",
    "y_all = test.iloc[:, 12:16].values\n",
    "y_all = y_all.reshape(-4, 4)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_smass = torch.tensor(y_smass, dtype=torch.float32)\\ny_color = torch.tensor(y_color, dtype=torch.float32)\\ny_smass_color = torch.tensor(y_smass_color, dtype=torch.float32)\\ny_all = torch.tensor(y_all, dtype=torch.float32)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "'''\n",
    "y_smass = torch.tensor(y_smass, dtype=torch.float32)\n",
    "y_color = torch.tensor(y_color, dtype=torch.float32)\n",
    "y_smass_color = torch.tensor(y_smass_color, dtype=torch.float32)\n",
    "y_all = torch.tensor(y_all, dtype=torch.float32)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.2853],\n",
      "        [-4.8599],\n",
      "        [-4.9689],\n",
      "        ...,\n",
      "        [-5.7967],\n",
      "        [-3.4570],\n",
      "        [-4.6674]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_smass.eval()\n",
    "with torch.no_grad():\n",
    "    #taus = torch.rand(X_test.size(0), 1)\n",
    "    #augmented_x = augment(X_test, taus).to(device)\n",
    "    #print(augmented_x)\n",
    "    \n",
    "    y_pred_smass = model_smass(X_test)\n",
    "    y_pred_smass = y_pred_smass[:,1].unsqueeze(1)\n",
    "\n",
    "print(y_pred_smass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1873],\n",
      "        [0.2992],\n",
      "        [0.2214],\n",
      "        ...,\n",
      "        [0.2563],\n",
      "        [0.5997],\n",
      "        [0.3429]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_color.eval()\n",
    "with torch.no_grad():\n",
    "    #taus = torch.rand(X_test.size(0), 1)\n",
    "    #augmented_x = augment(X_test, taus)\n",
    "    \n",
    "    y_pred_color = model_color(X_test)\n",
    "    y_pred_color = y_pred_color[:,1].unsqueeze(1)\n",
    "\n",
    "print(y_pred_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.7926, 1.5568],\n",
      "        [4.5638, 1.5204],\n",
      "        [4.2747, 1.6262],\n",
      "        ...,\n",
      "        [4.1250, 1.6632],\n",
      "        [6.0891, 1.5233],\n",
      "        [4.8662, 1.5610]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_smass_color.eval()\n",
    "with torch.no_grad():\n",
    "    #taus = torch.rand(X_test.size(0), 1)\n",
    "    #augmented_x = augment(X_test, taus)\n",
    "    \n",
    "    y_pred_smass_color = model_smass_color(X_test)\n",
    "    y_pred_smass_color1 = y_pred_smass_color[:,1].unsqueeze(1)\n",
    "    y_pred_smass_color2 = y_pred_smass_color[:,4].unsqueeze(1)\n",
    "    y_pred_smass_color = torch.cat((y_pred_smass_color1,y_pred_smass_color2),dim=1)\n",
    "print(y_pred_smass_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2.9647,   1.4900,   1.4709, -19.3170],\n",
      "        [  3.6639,   1.2555,   1.3222, -27.9792],\n",
      "        [  3.8699,   0.6349,   1.1446, -16.6758],\n",
      "        ...,\n",
      "        [  3.4608,   0.9242,   1.0403, -17.0275],\n",
      "        [  8.1574,   1.5130,   0.5430, -21.9711],\n",
      "        [  5.2318,   0.9945,   0.8449, -17.5298]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_all.eval()\n",
    "with torch.no_grad():\n",
    "    #taus = torch.rand(X_test.size(0), 1)\n",
    "    #augmented_x = augment(X_test, taus)\n",
    "    \n",
    "    y_pred_all = model_all(X_test)\n",
    "    y_pred_all1 = y_pred_all[:,1].unsqueeze(1)\n",
    "    y_pred_all2 = y_pred_all[:,4].unsqueeze(1)\n",
    "    y_pred_all3 = y_pred_all[:,7].unsqueeze(1)\n",
    "    y_pred_all4 = y_pred_all[:,10].unsqueeze(1)\n",
    "    y_pred_all = torch.cat((y_pred_all1,y_pred_all2,y_pred_all3,y_pred_all4),dim=1)\n",
    "\n",
    "print(y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26218, 2])\n",
      "torch.Size([26218, 2])\n"
     ]
    }
   ],
   "source": [
    "y_pred_smass_color_union = torch.cat((y_pred_smass,y_pred_color), dim=1)\n",
    "y_pred_all = y_pred_all[:,:2]\n",
    "\n",
    "print(y_pred_smass_color_union.shape)\n",
    "print(y_pred_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smass_color_joint = pd.DataFrame(y_pred_smass_color, columns=['stellar_mass', 'color_g_i'])\n",
    "df_smass_color_union = pd.DataFrame(y_pred_smass_color_union, columns=['stellar_mass', 'color_g_i'])\n",
    "df_smass_color_all = pd.DataFrame(y_pred_all, columns=['stellar_mass', 'color_g_i'])\n",
    "\n",
    "df_smass_color_joint.index = test.index\n",
    "df_smass_color_union.index = test.index\n",
    "df_smass_color_all.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smass_color_joint = pd.concat([test[['X_h', 'Y_h', 'Z_h']], df_smass_color_joint], axis=1)\n",
    "df_smass_color_union = pd.concat([test[['X_h', 'Y_h', 'Z_h']], df_smass_color_union], axis=1)\n",
    "df_smass_color_all = pd.concat([test[['X_h', 'Y_h', 'Z_h']], df_smass_color_all], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracers_definer(df):\n",
    "    tracers = {\n",
    "        1: df[(df['color_g_i'] > 1.05) & (df['stellar_mass'].between(9.5, 10.5))],\n",
    "        2: df[(df['color_g_i'] > 1.05) & (df['stellar_mass'] > 10.5)],\n",
    "        3: df[(df['color_g_i'].between(0.80, 1.05)) & (df['stellar_mass'] <= 9.5)],\n",
    "        4: df[(df['color_g_i'].between(0.80, 1.05)) & (df['stellar_mass'].between(9.5, 10.5))],\n",
    "        5: df[(df['color_g_i'].between(0.80, 1.05)) & (df['stellar_mass'] > 10.5)],\n",
    "        6: df[(df['color_g_i'] <= 0.80) & (df['stellar_mass'] <= 9.5)],\n",
    "        7: df[(df['color_g_i'] <= 0.80) & (df['stellar_mass'].between(9.5, 10.5))]\n",
    "    }\n",
    "    return tracers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tracers \u001b[38;5;241m=\u001b[39m tracers_definer(test)\n\u001b[0;32m----> 2\u001b[0m tracers_smass_color_joint \u001b[38;5;241m=\u001b[39m \u001b[43mtracers_definer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_smass_color_joint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tracers_smass_color_union \u001b[38;5;241m=\u001b[39m tracers_definer(df_smass_color_union)\n\u001b[1;32m      4\u001b[0m tracers_smass_color_all \u001b[38;5;241m=\u001b[39m tracers_definer(df_smass_color_all)\n",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m, in \u001b[0;36mtracers_definer\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtracers_definer\u001b[39m(df):\n\u001b[1;32m      2\u001b[0m     tracers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;241m1\u001b[39m: df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_g_i\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.05\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstellar_mass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m9.5\u001b[39m, \u001b[38;5;241m10.5\u001b[39m))],\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m2\u001b[39m: df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_g_i\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.05\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstellar_mass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10.5\u001b[39m)],\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;241m3\u001b[39m: df[(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolor_g_i\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbetween\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.05\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstellar_mass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9.5\u001b[39m)],\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;241m4\u001b[39m: df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_g_i\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m0.80\u001b[39m, \u001b[38;5;241m1.05\u001b[39m)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstellar_mass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m9.5\u001b[39m, \u001b[38;5;241m10.5\u001b[39m))],\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;241m5\u001b[39m: df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_g_i\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m0.80\u001b[39m, \u001b[38;5;241m1.05\u001b[39m)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstellar_mass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10.5\u001b[39m)],\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;241m6\u001b[39m: df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_g_i\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.80\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstellar_mass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9.5\u001b[39m)],\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;241m7\u001b[39m: df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor_g_i\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.80\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstellar_mass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m9.5\u001b[39m, \u001b[38;5;241m10.5\u001b[39m))]\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tracers\n",
      "File \u001b[0;32m~/anaconda3/envs/galaxias/lib/python3.8/site-packages/pandas/core/series.py:4364\u001b[0m, in \u001b[0;36mSeries.between\u001b[0;34m(self, left, right, inclusive)\u001b[0m\n\u001b[1;32m   4298\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4299\u001b[0m \u001b[38;5;124;03mReturn boolean Series equivalent to left <= series <= right.\u001b[39;00m\n\u001b[1;32m   4300\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4361\u001b[0m \u001b[38;5;124;03mdtype: bool\u001b[39;00m\n\u001b[1;32m   4362\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inclusive:\n\u001b[0;32m-> 4364\u001b[0m     lmask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\n\u001b[1;32m   4365\u001b[0m     rmask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m right\n\u001b[1;32m   4366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/galaxias/lib/python3.8/site-packages/pandas/core/ops/common.py:64\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     62\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/galaxias/lib/python3.8/site-packages/pandas/core/ops/__init__.py:529\u001b[0m, in \u001b[0;36m_comp_method_SERIES.<locals>.wrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    526\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m extract_array(\u001b[38;5;28mself\u001b[39m, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    527\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 529\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _construct_result(\u001b[38;5;28mself\u001b[39m, res_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/galaxias/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:247\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    244\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(lvalues\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m--> 247\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     op_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/galaxias/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:57\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     55\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tracers = tracers_definer(test)\n",
    "tracers_smass_color_joint = tracers_definer(df_smass_color_joint)\n",
    "tracers_smass_color_union = tracers_definer(df_smass_color_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el número de objetos en cada trazador\n",
    "for i in range(1, 8):\n",
    "    print(f'Trazador {i}: {len(tracers[i])} objetos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el número de objetos en cada trazador\n",
    "for i in range(1, 8):\n",
    "    print(f'Trazador {i}: {len(tracers_smass_color_joint[i])} objetos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el número de objetos en cada trazador\n",
    "for i in range(1, 8):\n",
    "    print(f'Trazador {i}: {len(tracers_smass_color_union[i])} objetos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular el espectro de potencia de un trazador dado\n",
    "def calculate_power_spectrum(tracer_df):\n",
    "    # Obtener posiciones de los halos\n",
    "    positions = tracer_df[['X_h', 'Y_h', 'Z_h']].values #Para el original deben ser los de las galaxias reales\n",
    "    # Crear un catálogo de nbodykit con las posiciones\n",
    "    cat = ArrayCatalog({'Position': positions}, BoxSize=[205.0, 205.0, 205.0])\n",
    "    # Convertir el catálogo a una malla\n",
    "    mesh = cat.to_mesh(Nmesh=256, window='tsc')\n",
    "    # Calcular el espectro de potencia 1D\n",
    "    r = FFTPower(mesh, mode='1d')\n",
    "    power = r.power\n",
    "    # Obtener los valores de k y P(k)\n",
    "    k = power['k']\n",
    "    pk = power['power'].real - power.attrs['shotnoise']\n",
    "    return k, pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los espectros de potencia para cada trazador\n",
    "power_spectra = {}\n",
    "for alpha, df in tracers.items():\n",
    "    k, pk = calculate_power_spectrum(df)\n",
    "    power_spectra[alpha] = (k, pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los espectros de potencia para cada trazador\n",
    "power_spectra_joint = {}\n",
    "for alpha, df in tracers_smass_color_joint.items():\n",
    "    k, pk = calculate_power_spectrum(df)\n",
    "    power_spectra_joint[alpha] = (k, pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los espectros de potencia para cada trazador\n",
    "power_spectra_union = {}\n",
    "for alpha, df in tracers_smass_color_union.items():\n",
    "    k, pk = calculate_power_spectrum(df)\n",
    "    power_spectra_union[alpha] = (k, pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular los valores de sigma² para cada trazador\n",
    "def calculate_sigma(tracer_df, pk):\n",
    "    # Número de trazadores\n",
    "    n_alpha = len(tracer_df)\n",
    "    # Volumen de la caja\n",
    "    volume = 205.0**3\n",
    "    # Densidad numérica promedio\n",
    "    n_bar = n_alpha / volume\n",
    "    k_values = pk[0]\n",
    "    p_values = pk[1]\n",
    "    # Delta k (diferencia entre valores consecutivos de k)\n",
    "    delta_k = k_values[1] - k_values[0]\n",
    "    # Volumen en el espacio k\n",
    "    V_k = 4 * np.pi * k_values**2 * delta_k / (2 * np.pi)**3\n",
    "    # Calcular sigma²\n",
    "    sigma2_alpha_i = (2 / V_k) * ((1 + n_bar * p_values) / (n_bar * p_values))**2\n",
    "    return sigma2_alpha_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los valores de sigma² para cada trazador\n",
    "sigma_values_joint = {}\n",
    "for alpha, df in tracers_smass_color_joint.items():\n",
    "    sigma2_alpha_i = calculate_sigma(df, power_spectra_joint[alpha])\n",
    "    sigma_values_joint[alpha] = sigma2_alpha_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los valores de sigma² para cada trazador\n",
    "sigma_values_union = {}\n",
    "for alpha, df in tracers_smass_color_union.items():\n",
    "    sigma2_alpha_i = calculate_sigma(df, power_spectra_union[alpha])\n",
    "    sigma_values_union[alpha] = sigma2_alpha_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los valores de sigma² para cada trazador\n",
    "sigma_values_all = {}\n",
    "for alpha, df in tracers_smass_color_all.items():\n",
    "    sigma2_alpha_i = calculate_sigma(df, power_spectra_all[alpha])\n",
    "    sigma_values_all[alpha] = sigma2_alpha_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los valores de sigma² para cada trazador\n",
    "sigma_values = {}\n",
    "for alpha, df in tracers.items():\n",
    "    sigma2_alpha_i = calculate_sigma(df, power_spectra[alpha])\n",
    "    sigma_values[alpha] = sigma2_alpha_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una figura grande con subgráficos organizados en una cuadrícula\n",
    "fig, axs = plt.subplots(7, 2, figsize=(10, 20), facecolor='white')\n",
    "\n",
    "for i, alpha in enumerate(range(1, 8)):\n",
    "    # Subgráfico 1: P(k) vs k\n",
    "    k, pk_tng300 = power_spectra[alpha]\n",
    "    k_union, pk_union = power_spectra_union[alpha]\n",
    "    k_joint, pk_joint = power_spectra_joint[alpha]\n",
    "    k_all, pk_all = power_spectra_all[alpha]\n",
    "    \n",
    "    axs[i, 0].plot(k, pk_tng300, label=f'Tracer {alpha} TNG300', color='#000000')\n",
    "    axs[i, 0].plot(k_union, pk_union, label=f'Tracer {alpha} UNION', linestyle='--', color='#924fdc')\n",
    "    axs[i, 0].plot(k_joint, pk_joint, label=f'Tracer {alpha} JOINT', linestyle='--', color='#fd75ca')\n",
    "    axs[i, 0].plot(k_all, pk_all, label=f'Tracer {alpha} ALL', linestyle='--', color='#2bffd2')\n",
    "    \n",
    "    axs[i, 0].set_xlabel('k [h/Mpc]')\n",
    "    axs[i, 0].set_ylabel('P(k) [(Mpc/h)^3]')\n",
    "    axs[i, 0].set_xscale('log')\n",
    "    axs[i, 0].set_yscale('log')\n",
    "    axs[i, 0].set_title(f'Power Spectra for Tracer {alpha}')\n",
    "    axs[i, 0].legend()\n",
    "    axs[i, 0].grid(True)\n",
    "\n",
    "    # Establecer los límites de los ejes\n",
    "    axs[i, 0].set_xlim(0.08, 0.5)\n",
    "    axs[i, 0].set_ylim(1e2, 1e5)\n",
    "\n",
    "    # Establecer los ticks en los ejes\n",
    "    axs[i, 0].set_xticks([0.1, 0.2, 0.4])\n",
    "    axs[i, 0].set_xticklabels(['0.1', '0.2', '0.4'])\n",
    "    axs[i, 0].set_yticks([1e2, 1e3, 1e4, 1e5])\n",
    "    axs[i, 0].set_yticklabels(['1e2', '1e3', '1e4', '1e5'])\n",
    "    \n",
    "    # Controlar el formato de los ticks en el eje x usando MaxNLocator\n",
    "    axs[i, 0].xaxis.set_major_locator(MaxNLocator(integer=False, prune='both'))\n",
    "    \n",
    "    axs[i, 0].grid(False, which='both', axis='x')\n",
    "    \n",
    "    for tick in [0.1, 0.2, 0.4]:\n",
    "        axs[i, 0].axvline(x=tick, color='gray', linestyle='--', linewidth=0.7)\n",
    "\n",
    "    sigma2_alpha_i = sigma_values[alpha]\n",
    "\n",
    "    residual_union = (pk_union - pk_tng300)**2 / sigma2_alpha_i\n",
    "    residual_joint = (pk_joint - pk_tng300)**2 / sigma2_alpha_i\n",
    "    residual_all = (pk_all - pk_tng300)**2 / sigma2_alpha_i\n",
    "    axs[i, 1].plot(k_union, residual_union, label=f'Tracer {alpha}', color='#924fdc')\n",
    "    axs[i, 1].plot(k_joint, residual_joint, label=f'Tracer {alpha}', color='#fd75ca')\n",
    "    axs[i, 1].plot(k_all, residual_all, label=f'Tracer {alpha}', color='#2bffd2')\n",
    "    \n",
    "\n",
    "    \n",
    "    chi2_value_union = np.sum(residual_union)\n",
    "    chi2_value_joint = np.sum(residual_joint)\n",
    "    chi2_value_all = np.sum(residual_all)\n",
    "    \n",
    "    # Añadir el valor de chi cuadrado como texto en el gráfico\n",
    "    table_str = (\n",
    "        r'$\\chi^2_{union} = ' + f'{chi2_value_union:.2f}$' '\\n'\n",
    "        r'$\\chi^2_{joint} = ' + f'{chi2_value_joint:.2f}$' '\\n'\n",
    "        r'$\\chi^2_{all} = ' + f'{chi2_value_all:.2f}$'\n",
    "    )\n",
    "    axs[i, 1].text(0.05, 0.95, table_str, transform=axs[i, 1].transAxes, fontsize= 8, \n",
    "                verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white'))\n",
    "    \n",
    "    axs[i, 1].set_xlabel('k [h/Mpc]')\n",
    "    axs[i, 1].set_ylabel(r'$\\frac{(P_x - P_t)^2}{\\sigma_x^2}$')\n",
    "    axs[i, 1].set_xscale('log')\n",
    "    axs[i, 1].set_yscale('log')\n",
    "    axs[i, 1].set_title(f'Residuals for Tracer {alpha}')\n",
    "    axs[i, 1].legend()\n",
    "    axs[i, 1].grid(True)\n",
    "\n",
    "    axs[i, 1].set_xlim(0.08, 0.5)\n",
    "\n",
    "    axs[i, 1].set_xticks([0.1, 0.2, 0.4])\n",
    "    axs[i, 1].set_xticklabels(['0.1', '0.2', '0.4'])\n",
    "\n",
    "    axs[i, 1].xaxis.set_major_locator(MaxNLocator(integer=False, prune='both'))\n",
    "    \n",
    "    axs[i, 1].grid(False, which='both', axis='x')\n",
    "    \n",
    "    for tick in [0.1, 0.2, 0.4]:\n",
    "        axs[i, 1].axvline(x=tick, color='gray', linestyle='--', linewidth=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Datos adicionales de ejemplo para otras líneas\n",
    "additional_data = {\n",
    "    'Extra 1': (np.logspace(-2, 1, 100), np.random.uniform(1e-1, 1e-3, 100)),\n",
    "    'Extra 2': (np.logspace(-2, 1, 100), np.random.uniform(1e-1, 1e-3, 100)),\n",
    "    'Extra 3': (np.logspace(-2, 1, 100), np.random.uniform(1e-1, 1e-3, 100)),\n",
    "}\n",
    "\n",
    "# Crear una figura grande con subgráficos organizados en una cuadrícula de 2 filas y 4 columnas\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10), facecolor='white')\n",
    "\n",
    "for i, alpha in enumerate(range(1, 8)):\n",
    "    row, col = divmod(i, 4)  # Calcular la fila y la columna del subgráfico actual\n",
    "    k, pk_tng300 = power_spectra[alpha]\n",
    "    k_union, pk_union = power_spectra_union[alpha]\n",
    "    k_joint, pk_joint = power_spectra_joint[alpha]\n",
    "    k_all, pk_all = power_spectra_all[alpha]\n",
    "\n",
    "    sigma2_alpha_i = sigma_values[alpha]\n",
    "    sigma2_alpha_i_union = sigma_values_union[alpha]\n",
    "    sigma2_alpha_i_joint = sigma_values_joint[alpha]\n",
    "    sigma2_alpha_i_all = sigma_values_all[alpha]\n",
    "    ratio = sigma2_alpha_i / pk_tng300**2\n",
    "    ratio_union = sigma2_alpha_i_union / pk_union**2\n",
    "    ratio_joint = sigma2_alpha_i_joint / pk_joint**2\n",
    "    ratio_all = sigma2_alpha_i_all / pk_all**2\n",
    "    \n",
    "    # Graficar los datos originales\n",
    "    axs[row, col].plot(k, ratio, label=f'Tracer {alpha}', color='blue')  # Línea principal\n",
    "    axs[row, col].plot(k_union, ratio_union, label=f'Tracer {alpha} UNION', color='#924fdc')\n",
    "    axs[row, col].plot(k_joint, ratio_joint, label=f'Tracer {alpha} JOINT', color='#fd75ca')\n",
    "    axs[row, col].plot(k_all, ratio_all, label=f'Tracer {alpha} ALL', color='#2bffd2')\n",
    "    \n",
    "    \n",
    "    axs[row, col].set_xlabel('k [h/Mpc]')\n",
    "    axs[row, col].set_ylabel(r'$\\frac{\\sigma_x^2 (k)}{P_t^2 (k)}$')\n",
    "    axs[row, col].set_xscale('log')\n",
    "    axs[row, col].set_yscale('log')\n",
    "    axs[row, col].set_title(f'Tracer {alpha}')\n",
    "    axs[row, col].legend()\n",
    "    \n",
    "    axs[row, col].grid(False, which='both', axis='x')\n",
    "    axs[row, col].set_xlim(0.08, 0.5)\n",
    "    axs[row, col].set_ylim(1e-3, 1e0)\n",
    "\n",
    "    # Establecer los ticks en los ejes\n",
    "    axs[row, col].set_xticks([0.1, 0.2, 0.4])\n",
    "    axs[row, col].set_xticklabels(['0.1', '0.2', '0.4'])\n",
    "    axs[row, col].set_yticks([1e-3, 1e-2, 1e-1, 1])\n",
    "    axs[row, col].set_yticklabels(['1e-3', '1e-2', '1e-1', ''])\n",
    "    \n",
    "    axs[row, col].xaxis.set_major_locator(MaxNLocator(integer=False, prune='both'))\n",
    "    \n",
    "    for tick in [0.1, 0.2, 0.4]:\n",
    "        axs[row, col].axvline(x=tick, color='gray', linestyle='--', linewidth=0.7)\n",
    "    \n",
    "    for tick in [1e-3, 1e-2, 1e-1, 1]:\n",
    "        axs[row, col].axhline(y=tick, color='gray', linestyle='--', linewidth=0.7)\n",
    "\n",
    "    \n",
    "\n",
    "# Eliminar el último subgráfico vacío si el número de trazadores es menor al total de subgráficos\n",
    "if len(range(1, 8)) < 8:\n",
    "    fig.delaxes(axs[1, 3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7, 2, figsize=(10, 20), facecolor='white')  # 7 filas y 2 columnas para mantener la altura\n",
    "\n",
    "for i, alpha in enumerate(range(1, 8)):\n",
    "    row, col = divmod(i, 2)  # Calcular la fila y la columna del subgráfico actual\n",
    "\n",
    "    k_union, pk_union = power_spectra_union[alpha]\n",
    "    k_joint, pk_joint = power_spectra_joint[alpha]\n",
    "    #k_joint_wass, pk_joint_wass = power_spectra_joint_wass[alpha]\n",
    "    k_paper, pk_paper = power_spectra_paper[alpha]\n",
    "\n",
    "    sigma2_alpha_i_union = sigma_values_union[alpha]\n",
    "    sigma2_alpha_i_joint = sigma_values_joint[alpha]\n",
    "    #sigma2_alpha_i_joint_wass = sigma_values_joint_wass[alpha]\n",
    "    sigma2_alpha_i_paper = sigma_values_paper[alpha]\n",
    "\n",
    "    ratio_union = sigma2_alpha_i_union / pk_union**2\n",
    "    ratio_joint = sigma2_alpha_i_joint / pk_joint**2\n",
    "    #ratio_joint_wass = sigma2_alpha_i_joint_wass / pk_joint_wass**2\n",
    "    ratio_paper = sigma2_alpha_i_paper / pk_paper**2\n",
    "    \n",
    "    # Graficar los datos originales\n",
    "    axs[row, col].plot(k_union, ratio_union, label=f'Tracer {alpha} UNION', color='#924fdc')\n",
    "    axs[row, col].plot(k_joint, ratio_joint, label=f'Tracer {alpha} JOINT', color='#fd75ca')\n",
    "    #axs[row, col].plot(k_joint_wass, ratio_joint_wass, label=f'Tracer {alpha} ALL', color='#2bffd2')\n",
    "    axs[row, col].plot(k_paper, ratio_paper, label=f'Tracer {alpha} PAPER', color='#ff9e8b')\n",
    "    \n",
    "    axs[row, col].set_xlabel('k [h/Mpc]')\n",
    "    axs[row, col].set_ylabel(r'$\\sigma_x^2 (k) / P_T^2 (k)$')\n",
    "    axs[row, col].set_xscale('log')\n",
    "    axs[row, col].set_yscale('log')\n",
    "    axs[row, col].set_title(f'Tracer {alpha}')\n",
    "    axs[row, col].legend()\n",
    "    \n",
    "    axs[row, col].grid(False, which='both', axis='x')\n",
    "    axs[row, col].set_xlim(0.08, 0.5)\n",
    "    axs[row, col].set_ylim(1e-3, 1e0)\n",
    "\n",
    "    # Establecer los ticks en los ejes\n",
    "    axs[row, col].set_xticks([0.1, 0.2, 0.4])\n",
    "    axs[row, col].set_xticklabels(['0.1', '0.2', '0.4'])\n",
    "    axs[row, col].set_yticks([1e-3, 1e-2, 1e-1, 1])\n",
    "    axs[row, col].set_yticklabels([r'$10^{-3}$', r'$10^{-2}$', r'$10^{-1}$', r'$10^{0}$'])\n",
    "    \n",
    "    axs[row, col].xaxis.set_major_locator(MaxNLocator(integer=False, prune='both'))\n",
    "    \n",
    "    for tick in [0.1, 0.2, 0.4]:\n",
    "        axs[row, col].axvline(x=tick, color='gray', linestyle='--', linewidth=0.7)\n",
    "    \n",
    "    for tick in [1e-3, 1e-2, 1e-1, 1]:\n",
    "        axs[row, col].axhline(y=tick, color='gray', linestyle='--', linewidth=0.7)\n",
    "\n",
    "# Desactivar los subgráficos vacíos\n",
    "for j in range(i + 1, 7 * 2):  # 7 filas * 2 columnas = 14 subgráficos en total\n",
    "    fig.delaxes(axs.flat[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
